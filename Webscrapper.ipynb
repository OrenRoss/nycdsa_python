{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "654e3bf3-caf6-4ca4-a612-a4798f97d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import csv\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68329191-d4e1-4eee-bbbf-4a061d378c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_book_results_page(page_num, headers = headers):\n",
    "    \"\"\"\n",
    "    docstring\n",
    "    \n",
    "    ARGS:\n",
    "    Page Number - integer that is the page number to scrape\n",
    "    Header dictionary -\n",
    "    \n",
    "    Return-\n",
    "    Dictionary named \"page_(page_num)_dict\" with following keys-\n",
    "    Page URL - The URL of the books results page \n",
    "    Response - object\n",
    "    soup - beautiful soup object\n",
    "    book_urls - list of url for each book on page \n",
    "    \"\"\"\n",
    "    from bs4 import BeautifulSoup\n",
    "    # Make sure page_num is an integer\n",
    "    if not isinstance(page_num, int):\n",
    "        raise ValueError(\"Page number must be an integer!\")\n",
    "        \n",
    "    # Checking response code to make sure not creating a problem\n",
    "    \n",
    "#     Page 1 and then 2\n",
    "#     https://www.metacritic.com/browse/games/score/metascore/all/all/filtered\n",
    "#     https://www.metacritic.com/browse/games/score/metascore/all/all/filtered?page=1\n",
    "\n",
    "### will need to scrape from the browsing page.\n",
    "      \n",
    "    response = requests.get(f'https://www.metacritic.com/browse/games/score/metascore/all/all/filtered?page={page_num}', headers = headers)\n",
    "    if response.status_code >= 400:\n",
    "        raise ValueError(f'RESPONSE CODE ERROR: {response.status_code}')\n",
    "                                                 \n",
    "    #Creating a beautiful soup object\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                         ### STARTING TO SCRAPE BOOK URLS ###\n",
    "    # Empty list for the book urls                 \n",
    "#     game_results_urls = []\n",
    "                     \n",
    "#     # Finding the header that contains title name and link to page\n",
    "#     book_divs = soup.find_all('div', attrs = {'class': 'image_container'})\n",
    "#     book_urls = [tag.find('a').get('href') for tag in book_divs]\n",
    "#     book_page_urls = []\n",
    "\n",
    "#     # Adding the link to the url for scrapping\n",
    "#     book_page_urls.append([f'https://books.toscrape.com/catalogue/{end_part}' for end_part in book_urls])\n",
    "\n",
    "    \n",
    "    return soup    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77bfdce-ca97-4bbf-b744-f1ae634f2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"scrape_book_product_page(book_product_url, headers)`: This function takes a book product URL (the URL for the book product page) and a headers dictionary as arguments and returns a dictionary with the following keys:\n",
    "    - `book_url`: The URL of the book product page \n",
    "    - `response`: The Response object of that page\n",
    "    - `soup`: The BeautifulSoup object created from the source code\n",
    "\"\"\"\n",
    "\n",
    "def scrape_book_product_page(results_soup, headers=headers):\n",
    "    \"\"\"\n",
    "    DOC STRING\n",
    "    \n",
    "    ARGS:\n",
    "    book_product_url - the url for a specific book's product page\n",
    "    headers - (dictionary) - the header to be used\n",
    "    \n",
    "    RETURN:\n",
    "    A dictionary with the following results-\n",
    "    book_url - a return of the original arg\n",
    "    response - response object\n",
    "    soup - beautiful soup object\n",
    "    \"\"\"\n",
    "    from bs4 import BeautifulSoup  \n",
    "    import re\n",
    "    from word2number import w2n\n",
    "\n",
    "    # Checking response code to make sure not creating a problem\n",
    "    game_list = []\n",
    "\n",
    "#     for x in book_url:\n",
    "#         book_dict = {}\n",
    "#         response = requests.get(x, headers = headers)\n",
    "#         if response.status_code >= 400:\n",
    "#             raise ValueError(f'RESPONSE CODE ERROR: {response.status_code}')\n",
    "         \n",
    "    \n",
    "        smaple_list=[]\n",
    "        for tag in tags.findAll('div', attrs={'td class': 'clamp-summary-wrap'}):\n",
    "            new_tag = tag.find('a', attrs={'class': 'uc-listingCard-title'})\n",
    "            print(new_tag.text)\n",
    "        \n",
    "        each game has own - \n",
    "            'div', attrs={'td class': 'clamp-summary-wrap'\n",
    "        game_title = ('h3')\n",
    "        platform = div class=\"platform\" - span class=\"data\"\n",
    "        release = div class=\"clamp-details\" - span (date in full form)\n",
    "        \n",
    "        rating - div class=\"clamp-score-wrap\"\n",
    "                          div class=\"meta_w large game (positve, neutral, or negative)\"\n",
    "        \n",
    "        if click expand -div class=\"clamp-score-wrap\"\n",
    "                          div class=\"meta_w user large game (positve, neutral, or negative)\"\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         #Creating a beautiful soup object\n",
    "        book_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "                           # get the title\n",
    "        book_dict['title'] = book_soup.find('div', attrs = {'class': 'col-sm-6 product_main'}).find('h1').string\n",
    "\n",
    "                           # Get price as float\n",
    "        book_dict['price_in_pounds'] = [float(s) for s in re.findall(r'-?\\d+\\.?\\d*', (book_soup.find('p', attrs = {'class':'price_color'}).string))]\n",
    "\n",
    "                    # Get average rating\n",
    "        avg_rating_tag = book_soup.find(lambda tag: 'star-rating' in tag.get('class') if tag.get('class') else False)\n",
    "        book_dict['avg_rating'] = w2n.word_to_num(avg_rating_tag.get('class')[1])       \n",
    "\n",
    "                    # Get genre\n",
    "        li_tag = book_soup.find('ul', attrs={'class':'breadcrumb'}).find_all('li')[2]\n",
    "        book_dict['genre'] = li_tag.find('a').string\n",
    "\n",
    "                    # Get UPC\n",
    "        tr_tag = book_soup.find('table', attrs = {'class':'table table-striped'}).find_all('tr')[0]\n",
    "        book_dict['upc'] = tr_tag.find('td').string\n",
    "\n",
    "                    # Get number of books available\n",
    "        books_avail = str.strip(book_soup.find('p', attrs = {'class':'instock availability'}).get_text())\n",
    "        book_dict['num_books_available'] =  [float(s) for s in re.findall(r'\\d+', books_avail)]\n",
    "        \n",
    "        book_list.append(book_dict)                                                                     \n",
    "\n",
    "    return book_list "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
